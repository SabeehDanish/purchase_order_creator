import fitz # PyMuPDF
import camelot
import pandas as pd
import re
import os
from fpdf import FPDF
from fpdf.enums import XPos, YPos
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional

# --- Configuration ---
# Set this to the PDF/CSV file you want to test
# For I/O South: TEST_FILE_NAME = '111651.pdf'
# For D&H: TEST_FILE_NAME = 'DandH-Quote-11931304-0.Pdf'
# For TD SYNNEX: TEST_FILE_NAME = 'email_quote_excel_cpo_42566579.xlsx - emailQuote.csv'
TEST_FILE_NAME = '111651.pdf' # <--- CHANGE THIS TO TEST DIFFERENT VENDORS

INPUT_FILE_PATH = os.path.join('PO\'s', TEST_FILE_NAME)

OUTPUT_DIR = 'generated_pos'
EXTRACTED_DATA_DIR = 'extracted_data'

if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)
if not os.path.exists(EXTRACTED_DATA_DIR):
    os.makedirs(EXTRACTED_DATA_DIR)

# --- Standardized Data Models (Phase 1, Point 2) ---
@dataclass
class LineItem:
    item_number: str
    description: str
    quantity: float
    unit_price: float
    line_total: float

@dataclass
class PurchaseOrder:
    po_number: str
    order_date: str
    vendor_name: str
    vendor_address: str
    vendor_phone: str
    vendor_website: Optional[str] = "Not Found"
    customer_name: Optional[str] = "Not Found" # FIXED: Added default value
    customer_address: Optional[str] = "Not Found"
    customer_phone: Optional[str] = "Not Found"
    line_items: List[LineItem] = field(default_factory=list)
    subtotal: float = 0.0
    tax: float = 0.0
    total: float = 0.0
    currency: str = "USD" # Default, update from extraction if possible

# --- Base Extractor Class (Phase 1, Point 1) ---
class PDFExtractor:
    def __init__(self, file_path: str):
        self.file_path = file_path
        if not os.path.exists(self.file_path):
            raise FileNotFoundError(f"File not found at {self.file_path}")
        self.text_content = ""
        self.pdf_blocks = []
        if self.file_path.lower().endswith('.pdf'):
            self._load_pdf_content()
        elif self.file_path.lower().endswith('.csv'):
            pass

    def _load_pdf_content(self):
        """Loads text content and blocks from the PDF."""
        with fitz.open(self.file_path) as doc:
            for page in doc:
                self.text_content += page.get_text()
            self.pdf_blocks = doc.load_page(0).get_text("blocks")

    def _get_camelot_table_areas(self) -> List[str]:
        """Returns Camelot table area coordinates specific to the vendor."""
        raise NotImplementedError("Subclasses must implement _get_camelot_table_areas")

    def _extract_line_items(self) -> List[LineItem]:
        """Extracts and cleans line items using Camelot (for PDFs) or Pandas (for CSVs)."""
        raise NotImplementedError("Subclasses must implement _extract_line_items")

    def _clean_line_items_dataframe(self, df: pd.DataFrame, expected_headers: Dict[str, str]) -> List[LineItem]:
        """
        Generic cleaning and conversion of DataFrame to LineItem objects.
        `expected_headers` maps raw column names to standardized ones.
        """
        print(f"--- Cleaning Line Items for {self.__class__.__name__} ---")
        renamed_df = df.rename(columns=expected_headers)

        if 'item_number' in renamed_df.columns:
            renamed_df = renamed_df[renamed_df['item_number'].astype(str).str.strip() != ''].copy()

        numeric_cols = ['quantity', 'unit_price', 'line_total']
        for col in numeric_cols:
            if col in renamed_df.columns:
                renamed_df[col] = renamed_df[col].astype(str).str.replace(r'[$,%T\s]', '', regex=True).str.strip()
                renamed_df[col] = pd.to_numeric(renamed_df[col], errors='coerce').fillna(0)
            else:
                renamed_df[col] = 0.0

        line_items_list = []
        for _, row in renamed_df.iterrows():
            item = LineItem(
                item_number=str(row.get('item_number', '')),
                description=str(row.get('description', '')),
                quantity=float(row.get('quantity', 0.0)),
                unit_price=float(row.get('unit_price', 0.0)),
                line_total=float(row.get('line_total', 0.0))
            )
            line_items_list.append(item)
        return line_items_list


    def _extract_header_data(self) -> Dict[str, Any]:
        """Extracts non-tabular header information specific to the vendor."""
        raise NotImplementedError("Subclasses must implement _extract_header_data")

    def extract_purchase_order(self) -> Optional[PurchaseOrder]:
        """Main method to extract all PO data."""
        try:
            line_items = self._extract_line_items()
            header_data = self._extract_header_data()

            if not line_items and not header_data:
                print("Failed to extract any data. Cannot create Purchase Order object.")
                return None

            subtotal = sum(item.line_total for item in line_items)
            extracted_tax = float(str(header_data.get('tax', 0.0)).replace('$', '').replace(',', '').strip())
            total = subtotal + extracted_tax

            po = PurchaseOrder(
                po_number=header_data.get('quote_number', 'N/A'),
                order_date=header_data.get('quote_date', 'N/A'),
                vendor_name=header_data.get('vendor_name', 'N/A'),
                vendor_address=header_data.get('vendor_address', 'N/A'),
                vendor_phone=header_data.get('vendor_phone', 'N/A'),
                vendor_website=header_data.get('vendor_website', 'Not Found'),
                customer_name=header_data.get('customer_name', 'Not Found'), # FIXED: Ensure default 'Not Found'
                customer_address=header_data.get('customer_address', 'Not Found'),
                customer_phone=header_data.get('customer_phone', 'Not Found'),
                line_items=line_items,
                subtotal=subtotal,
                tax=extracted_tax,
                total=total,
                currency=header_data.get('currency', 'USD')
            )
            print("\n--- Purchase Order Data Extracted Successfully ---")
            print(f"PO Number: {po.po_number}")
            print(f"Vendor: {po.vendor_name}")
            print(f"Vendor Address: {po.vendor_address}")
            print(f"Vendor Phone: {po.vendor_phone}")
            print(f"Vendor Website: {po.vendor_website}")
            print(f"Customer: {po.customer_name}")
            print(f"Customer Address: {po.customer_address}")
            print(f"Total Lines: {len(po.line_items)}")
            print(f"Calculated Total Value: ${po.total:,.2f} {po.currency}")

            return po

        except Exception as e:
            print(f"Error during overall PO extraction for {self.__class__.__name__}: {e}")
            return None


# --- I/O South Specific Extractor ---
class IOSouthExtractor(PDFExtractor):
    def _get_camelot_table_areas(self) -> List[str]:
        # Corrected area: [x_start, y_top, x_end, y_bottom] where y_top is numerically smaller
        return ['10,200,590,750']

    def _extract_line_items(self) -> List[LineItem]:
        print(f"--- Extracting Line Items for {self.__class__.__name__} ---")
        try:
            tables = camelot.read_pdf(
                self.file_path,
                pages='1',
                flavor='stream',
                table_areas=self._get_camelot_table_areas(),
                strip_text='\n'
            )
            if not tables:
                print("No tables found by Camelot for I/O South layout.")
                return []

            df = tables[0].df
            print("\n--- Raw Extracted Table (First Few Rows - BEFORE HEADER PROCESSING - I/O South): ---")
            print(df.head(20))

            header_row_index = -1
            for i, row in df.iterrows():
                row_str = " ".join(row.astype(str)).lower()
                if 'item' in row_str and 'description' in row_str and 'qty' in row_str and 'cost' in row_str and 'total' in row_str:
                    header_row_index = i
                    break

            if header_row_index == -1:
                print(f"Could not find expected table header for {self.__class__.__name__}.")
                print("Falling back to assuming header is on row 12 (0-indexed).")
                header_row_index = 12

            df.columns = df.iloc[header_row_index]
            df = df[header_row_index + 1:].reset_index(drop=True)
            df.dropna(how='all', inplace=True)

            cleaned_rows = []
            current_item = {}

            COL_ITEM = 'Item'
            COL_DESC = 'Description'
            COL_QTY = 'Qty'
            COL_COST = 'Cost'
            COL_TOTAL = 'Total'

            df_cols = df.columns.tolist()
            if not all(col in df_cols for col in [COL_ITEM, COL_DESC, COL_QTY, COL_COST, COL_TOTAL]):
                print("Error: Missing expected columns after header processing.")
                print("Available columns:", df_cols)
                return []

            for index, row in df.iterrows():
                item_number_val = str(row[COL_ITEM]).strip()
                description_val = str(row[COL_DESC]).strip()
                qty_val = str(row[COL_QTY]).strip()
                cost_val = str(row[COL_COST]).strip()
                total_val = str(row[COL_TOTAL]).strip()

                if item_number_val: # This is a new item
                    if current_item: # If there was a previous item, add it to cleaned_rows
                        cleaned_rows.append(current_item)
                    current_item = {
                        COL_ITEM: item_number_val,
                        COL_DESC: description_val,
                        COL_QTY: qty_val,
                        COL_COST: cost_val,
                        COL_TOTAL: total_val
                    }
                else: # This is a continuation of the previous item's description
                    if current_item and description_val:
                        current_item[COL_DESC] += "\n" + description_val

            if current_item: # Add the last item
                cleaned_rows.append(current_item)

            df_cleaned = pd.DataFrame(cleaned_rows)

            print("\n--- DataFrame After Header and Multi-Line Processing (I/O South): ---")
            print(df_cleaned.head())

            expected_headers = {
                'Item': 'item_number',
                'Description': 'description',
                'Qty': 'quantity',
                'Cost': 'unit_price',
                'Total': 'line_total'
            }
            df_cleaned = df_cleaned.loc[:, ~df_cleaned.columns.duplicated()]

            return self._clean_line_items_dataframe(df_cleaned, expected_headers)

        except Exception as e:
            print(f"Error during Camelot line item extraction for {self.__class__.__name__}: {e}")
            return []

    def _extract_header_data(self) -> Dict[str, Any]:
        """Extracts non-tabular header information specific to I/O South."""
        print(f"--- Extracting Header Data for {self.__class__.__name__} ---")
        header_data = {}
        text = self.text_content
        blocks = self.pdf_blocks
        try:
            # Date and Quote Number
            date_match = re.search(r'Date\s*(\d{1,2}/\d{1,2}/\d{4})', text)
            header_data['quote_date'] = date_match.group(1).strip() if date_match else "Not Found"

            quote_num_match = re.search(r'Quote #\s*(\d+)', text)
            header_data['quote_number'] = quote_num_match.group(1).strip() if quote_num_match else "Not Found"

            # Customer Name and Address
            customer_name_found = False
            customer_address_lines = []
            
            for i, b in enumerate(blocks):
                x0, y0, x1, y1, block_text, block_type, block_no = b
                if "Name / Address" in block_text:
                    if i + 1 < len(blocks):
                        customer_name_block = blocks[i+1]
                        if abs(customer_name_block[0] - x0) < 50:
                            header_data['customer_name'] = customer_name_block[4].strip()
                            customer_name_found = True
                            
                            j = i + 2
                            while j < len(blocks):
                                next_block = blocks[j]
                                if not next_block[4].strip() or \
                                   re.search(r'PO Number|Item|Description|Qty|Cost|Total|Rep|Project', next_block[4], re.IGNORECASE) or \
                                   (next_block[1] - blocks[j-1][3]) > 10 or \
                                   abs(next_block[0] - customer_name_block[0]) > 50:
                                    break
                                customer_address_lines.append(next_block[4].strip())
                                j += 1
                            break
            
            if customer_name_found:
                cleaned_address_lines = [line for line in customer_address_lines if line]
                header_data['customer_address'] = "\n".join(cleaned_address_lines) if cleaned_address_lines else "Not Found"
            else:
                header_data['customer_name'] = "Not Found"
                header_data['customer_address'] = "Not Found"

            # Vendor Name, Address, and Phone
            vendor_name_match = re.search(r'(I/O South, LLC)', text, re.MULTILINE)
            if vendor_name_match:
                header_data['vendor_name'] = vendor_name_match.group(1).strip()

                top_left_area_text = ""
                for b in blocks:
                    x0, y0, x1, y1, block_text, block_type, block_no = b
                    if x0 < 300 and y0 < 200:
                        top_left_area_text += block_text + "\n"

                address_phone_section = re.search(r'I/O South, LLC\s*\n(.*?)(?=\n(?:Date|Quote #|www\.iosouth\.com|Name / Address|\d{3}[-.\s]?\d{3}[-.\s]?\d{4}))', top_left_area_text, re.DOTALL)

                if address_phone_section:
                    address_content = address_phone_section.group(1).strip()
                    address_lines = [
                        line.strip() for line in address_content.split('\n')
                        if line.strip() and not re.search(r'^\(?\d{3}\)?[-\s.]?\d{3}[-\s.]?\d{4}$', line.strip())
                    ]
                    header_data['vendor_address'] = "\n".join(address_lines) if address_lines else "Not Found"
                else:
                    after_vendor_name_text = top_left_area_text[top_left_area_text.find("I/O South, LLC") + len("I/O South, LLC"):].strip()
                    address_lines_fallback = []
                    for line in after_vendor_name_text.split('\n'):
                        if not line.strip() or re.search(r'Date|Quote #|www\.|Name / Address|^\(?\d{3}\)?[-\s.]?\d{3}[-\s.]?\d{4}$', line, re.IGNORECASE):
                            break
                        address_lines_fallback.append(line.strip())
                    header_data['vendor_address'] = "\n".join(address_lines_fallback).strip()
                    if not header_data['vendor_address']:
                        header_data['vendor_address'] = "Not Found"

                phone_match = re.search(r'(\(?\d{3}\)?[-\s.]?\d{3}[-\s.]?\d{4})', top_left_area_text)
                header_data['vendor_phone'] = phone_match.group(1).strip() if phone_match else "Not Found"

                # Extract Vendor Website
                website_match = re.search(r'(www\.iosouth\.com)', top_left_area_text)
                header_data['vendor_website'] = website_match.group(1).strip() if website_match else "Not Found"


            else:
                header_data['vendor_name'] = "Not Found"
                header_data['vendor_address'] = "Not Found"
                header_data['vendor_phone'] = "Not Found"
                header_data['vendor_website'] = "Not Found"

            header_data['currency'] = "USD"
            header_data['tax'] = 0.0

        except Exception as e:
            print(f"Error during PyMuPDF header extraction for {self.__class__.__name__}: {e}")
            header_data.update({
                'quote_date': header_data.get('quote_date', 'Error'),
                'quote_number': header_data.get('quote_number', 'Error'),
                'customer_name': header_data.get('customer_name', 'Error'),
                'customer_address': header_data.get('customer_address', 'Error'),
                'vendor_name': header_data.get('vendor_name', 'Error'),
                'vendor_address': header_data.get('vendor_address', 'Error'),
                'vendor_phone': header_data.get('vendor_phone', 'Error'),
                'vendor_website': header_data.get('vendor_website', 'Error'),
                'currency': header_data.get('currency', 'Error'),
                'tax': header_data.get('tax', 0.0)
            })
        return header_data

# --- D&H Specific Extractor ---
class DandHExtractor(PDFExtractor):
    def _get_camelot_table_areas(self) -> List[str]:
        return ['0,200,800,100']

    def _extract_line_items(self) -> List[LineItem]:
        print(f"--- Extracting Line Items for {self.__class__.__name__} ---")
        try:
            tables = camelot.read_pdf(
                self.file_path,
                pages='1',
                flavor='stream',
                table_areas=self._get_camelot_table_areas(),
                strip_text='\n'
            )
            if not tables:
                print("No tables found by Camelot for D&H layout.")
                return []

            df = tables[0].df
            print("\n--- Raw Extracted Table (First Few Rows - D&H Camelot): ---")
            print(df.head(10))

            header_row_index = -1
            for i, row in df.iterrows():
                row_str = " ".join(row.astype(str)).lower()
                if 'ln' in row_str and 'description' in row_str and 'unit' in row_str and 'extended' in row_str:
                    header_row_index = i
                    break

            if header_row_index == -1:
                print(f"Could not find expected table header for {self.__class__.__name__}.")
                return []

            df.columns = df.iloc[header_row_index]
            df = df[header_row_index + 1:].reset_index(drop=True)
            df.dropna(how='all', inplace=True)

            expected_headers = {
                'Ln': 'item_number',
                'Description': 'description',
                'Ord': 'quantity',
                'Unit': 'unit_price',
                'Extended': 'line_total'
            }
            df = df.loc[:, ~df.columns.duplicated()]

            return self._clean_line_items_dataframe(df, expected_headers)

        except Exception as e:
            print(f"Error during Camelot line item extraction for {self.__class__.__name__}: {e}")
            return []

    def _extract_header_data(self) -> Dict[str, Any]:
        """Extracts non-tabular header information specific to D&H."""
        print(f"--- Extracting Header Data for {self.__class__.__name__} ---")
        header_data = {}
        text = self.text_content
        try:
            quote_num_match = re.search(r'Quote Number:\s*(\d+)', text)
            header_data['quote_number'] = quote_num_match.group(1).strip() if quote_num_match else "Not Found"

            date_match = re.search(r'Date:\s*(\d{2}/\d{2}/\d{4})', text)
            header_data['quote_date'] = date_match.group(1).strip() if date_match else "Not Found"

            header_data['vendor_name'] = "D&H Canada"
            header_data['vendor_website'] = "Not Found"
            
            vendor_address_match = re.search(r'MAIL: D&H Distributing \|(.*?)PHONE:', text, re.DOTALL)
            if vendor_address_match:
                address_content = vendor_address_match.group(1).strip()
                header_data['vendor_address'] = address_content.replace('\n', ', ')
            else:
                header_data['vendor_address'] = "Not Found"

            vendor_phone_match = re.search(r'PHONE: Sales and Credit: ([\d\s-]+)', text)
            header_data['vendor_phone'] = vendor_phone_match.group(1).strip() if vendor_phone_match else "Not Found"

            customer_name_match = re.search(r'Bill to Address:\s*\n(.*?)\nE-GATE NETWORKS INC', text, re.DOTALL)
            if customer_name_match:
                header_data['customer_name'] = customer_name_match.group(1).strip()
            else:
                header_data['customer_name'] = "Not Found"

            customer_address_match = re.search(r'Bill to Address:\s*\n(?:.*?)\n(.*?)\nNORTH YORK, ON M3A 2P8', text, re.DOTALL)
            if customer_address_match:
                address_lines = [line.strip() for line in customer_address_match.group(1).split('\n') if line.strip()]
                header_data['customer_address'] = "\n".join(address_lines)
            else:
                header_data['customer_address'] = "Not Found"

            merchandise_total_match = re.search(r'Merchandise Total\s*([\d,.]+)', text)
            header_data['subtotal'] = float(merchandise_total_match.group(1).replace(',', '')) if merchandise_total_match else 0.0

            tax_amount_match = re.search(r'Tax Amount\s*([\d,.]+)', text)
            header_data['tax'] = float(tax_amount_match.group(1).replace(',', '')) if tax_amount_match else 0.0

            quote_total_match = re.search(r'Quote Total\s*([\d,.]+)', text)
            header_data['total'] = float(quote_total_match.group(1).replace(',', '')) if quote_total_match else 0.0

            header_data['currency'] = "CAD"

        except Exception as e:
            print(f"Error during PyMuPDF header extraction for {self.__class__.__name__}: {e}")
            header_data = {
                'quote_date': 'Error', 'quote_number': 'Error', 'customer_name': 'Error',
                'vendor_name': 'Error', 'vendor_address': 'Error', 'vendor_phone': 'Error',
                'vendor_website': 'Error',
                'customer_address': 'Error', 'customer_phone': 'Error',
                'subtotal': 0.0, 'tax': 0.0, 'total': 0.0, 'currency': 'Error'
            }
        return header_data

# --- TD SYNNEX Specific Extractor (for CSV files) ---
class TDSynnexExtractor(PDFExtractor):
    def __init__(self, file_path: str):
        super().__init__(file_path)
        with open(self.file_path, 'r', encoding='utf-8') as f:
            self.csv_lines = f.readlines()
        self.full_csv_text = "".join(self.csv_lines)

    def _extract_line_items(self) -> List[LineItem]:
        print(f"--- Extracting Line Items for {self.__class__.__name__} ---")
        try:
            df = pd.read_csv(self.file_path, skiprows=15, header=0, encoding='utf-8')

            df = df.loc[:, ~df.columns.str.contains('^Unnamed')]

            print("\n--- Raw Extracted Table (First Few Rows - TD SYNNEX CSV): ---")
            print(df.head())

            expected_headers = {
                'Quote Line#': 'item_number',
                'Description': 'description',
                'Qty': 'quantity',
                'Reseller Price': 'unit_price',
                'Ext. Price': 'line_total'
            }

            return self._clean_line_items_dataframe(df, expected_headers)

        except Exception as e:
            print(f"Error during pandas line item extraction for {self.__class__.__name__}: {e}")
            return []

    def _extract_header_data(self) -> Dict[str, Any]:
        """Extracts non-tabular header information specific to TD SYNNEX from CSV lines."""
        print(f"--- Extracting Header Data for {self.__class__.__name__} ---")
        header_data = {}
        csv_text = self.full_csv_text

        try:
            quote_num_match = re.search(r'Quote#:\s*(\d+)', csv_text)
            header_data['quote_number'] = quote_num_match.group(1).strip() if quote_num_match else "Not Found"

            date_match = re.search(r'As of (\d{1,2}/\d{1,2}/\d{2,4})', csv_text)
            header_data['quote_date'] = date_match.group(1).strip() if date_match else "Not Found"

            header_data['vendor_name'] = "TD SYNNEX Corporation"
            header_data['vendor_website'] = "Not Found (Check Disclaimers)"
            
            header_data['vendor_address'] = "Not Found (Check Disclaimers)"
            header_data['vendor_phone'] = "Not Found"

            customer_name_match = re.search(r'Bill To:,,(.*?)\(', csv_text)
            header_data['customer_name'] = customer_name_match.group(1).strip() if customer_name_match else "Not Found"

            customer_address_match = re.search(r'Bill To:,,.*?\n,,(.*?)\n,,(.*?),', csv_text, re.DOTALL)
            if customer_address_match:
                address_line1 = customer_address_match.group(1).strip()
                address_line2 = customer_address_match.group(2).strip()
                header_data['customer_address'] = f"{address_line1}\n{address_line2}"
            else:
                header_data['customer_address'] = "Not Found"

            total_match = re.search(r'Total:.*?"\$([\d,\.]+)"', csv_text)
            header_data['total'] = float(total_match.group(1).replace('$', '').replace(',', '')) if total_match else 0.0
            header_data['subtotal'] = header_data['total']
            header_data['tax'] = 0.0

            currency_match = re.search(r'All prices are displayed in (CAD|USD)', csv_text)
            header_data['currency'] = currency_match.group(1) if currency_match else "USD"

        except Exception as e:
            print(f"Error during TD SYNNEX header extraction: {e}")
            header_data = {
                'quote_date': 'Error', 'quote_number': 'Error', 'customer_name': 'Error',
                'vendor_name': 'Error', 'vendor_address': 'Error', 'vendor_phone': 'Error',
                'vendor_website': 'Error',
                'customer_address': 'Error', 'customer_phone': 'Error',
                'subtotal': 0.0, 'tax': 0.0, 'total': 0.0, 'currency': 'Error'
            }
        return header_data


# --- PDF Generation Function (remains mostly generic, takes PurchaseOrder object) ---
def generate_po_pdf(po_data: PurchaseOrder, output_path: str):
    """Generates a new, clean PO PDF from the structured PurchaseOrder data."""
    pdf = FPDF()
    pdf.add_page()

    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.set_font("Helvetica", size=10)

    currency_symbol = "$"
    if po_data.currency == "CAD":
        currency_symbol = "C$"
    elif po_data.currency == "USD":
        currency_symbol = "$"

    # --- Vendor Information (Top Left) ---
    pdf.set_xy(10, 10)
    pdf.set_font("Helvetica", "B", 12)
    pdf.cell(0, 7, po_data.vendor_name, 0, new_x=XPos.LMARGIN, new_y=YPos.NEXT)
    pdf.set_font("Helvetica", size=10)
    for line in po_data.vendor_address.split('\n'):
        pdf.cell(0, 6, line, 0, new_x=XPos.LMARGIN, new_y=YPos.NEXT)
    pdf.cell(0, 6, f"Phone: {po_data.vendor_phone}", 0, new_x=XPos.LMARGIN, new_y=YPos.NEXT)
    if po_data.vendor_website and po_data.vendor_website != "Not Found":
        pdf.cell(0, 6, f"Website: {po_data.vendor_website}", 0, new_x=XPos.LMARGIN, new_y=YPos.NEXT)
    pdf.ln(5)

    # --- PO Header Information (Top Right) ---
    pdf.set_xy(130, 10)
    pdf.set_font("Helvetica", "B", 16)
    pdf.cell(0, 10, "PURCHASE ORDER", 0, new_x=XPos.LMARGIN, new_y=YPos.NEXT, align='R')
    pdf.ln(5)

    pdf.set_x(130)
    pdf.set_font("Helvetica", "B", 10)
    pdf.cell(0, 7, f"PO Number: {po_data.po_number}", 0, new_x=XPos.LMARGIN, new_y=YPos.NEXT, align='R')
    pdf.set_x(130)
    pdf.cell(0, 7, f"Date: {po_data.order_date}", 0, new_x=XPos.LMARGIN, new_y=YPos.NEXT, align='R')
    pdf.ln(10)

    # --- Ship To / Bill To (Customer) Information ---
    pdf.set_x(10)
    pdf.set_font("Helvetica", "B", 10)
    pdf.cell(0, 7, "Ship To / Bill To:", 0, new_x=XPos.LMARGIN, new_y=YPos.NEXT)
    pdf.set_font("Helvetica", size=10)
    pdf.cell(0, 6, po_data.customer_name, 0, new_x=XPos.LMARGIN, new_y=YPos.NEXT)
    for line in po_data.customer_address.split('\n'):
        pdf.cell(0, 6, line, 0, new_x=XPos.LMARGIN, new_y=YPos.NEXT)
    if po_data.customer_phone and po_data.customer_phone != "Not Found":
        pdf.cell(0, 6, f"Phone: {po_data.customer_phone}", 0, new_x=XPos.LMARGIN, new_y=YPos.NEXT)
    pdf.ln(10)

    # --- Line Items Table ---
    pdf.set_font("Helvetica", "B", 10)
    pdf.cell(25, 8, 'Item', 1, new_x=XPos.RIGHT, new_y=YPos.TOP, align='C')
    pdf.cell(90, 8, 'Description', 1, new_x=XPos.RIGHT, new_y=YPos.TOP, align='C')
    pdf.cell(15, 8, 'Qty', 1, new_x=XPos.RIGHT, new_y=YPos.TOP, align='C')
    pdf.cell(25, 8, 'Unit Price', 1, new_x=XPos.RIGHT, new_y=YPos.TOP, align='C')
    pdf.cell(30, 8, 'Line Total', 1, new_x=XPos.LMARGIN, new_y=YPos.NEXT, align='C')

    pdf.set_font("Helvetica", "", 9)
    for item in po_data.line_items:
        description_lines = item.description.split('\n')
        first_line = description_lines[0] if description_lines else ""
        remaining_lines = description_lines[1:] if len(description_lines) > 1 else []

        # First line of item: contains all data
        pdf.cell(25, 8, str(item.item_number), 1, align='L')
        pdf.cell(90, 8, first_line, 1, new_x=XPos.RIGHT, new_y=YPos.TOP, align='L')
        pdf.cell(15, 8, str(item.quantity), 1, new_x=XPos.RIGHT, new_y=YPos.TOP, align='C')
        pdf.cell(25, 8, f"{currency_symbol}{item.unit_price:,.2f}", 1, new_x=XPos.RIGHT, new_y=YPos.TOP, align='R')
        pdf.cell(30, 8, f"{currency_symbol}{item.line_total:,.2f}", 1, new_x=XPos.LMARGIN, new_y=YPos.NEXT, align='R')

        # Subsequent lines of description: only description, other cells empty
        for desc_line in remaining_lines:
            pdf.cell(25, 8, '', 0, new_x=XPos.RIGHT, new_y=YPos.TOP, align='L') # Empty cell for item
            pdf.cell(90, 8, desc_line, 1, new_x=XPos.RIGHT, new_y=YPos.TOP, align='L')
            pdf.cell(15, 8, '', 0, new_x=XPos.RIGHT, new_y=YPos.TOP, align='C') # Empty cell for Qty
            pdf.cell(25, 8, '', 0, new_x=XPos.RIGHT, new_y=YPos.TOP, align='R') # Empty cell for Unit Price
            pdf.cell(30, 8, '', 0, new_x=XPos.LMARGIN, new_y=YPos.NEXT, align='R') # Empty cell for Line Total


    # --- Totals Section ---
    pdf.ln(10)
    pdf.set_font("Helvetica", "B", 10)
    pdf.set_x(130)
    pdf.cell(35, 8, "Subtotal:", 0, new_x=XPos.RIGHT, new_y=YPos.TOP, align='R')
    pdf.cell(40, 8, f"{currency_symbol}{po_data.subtotal:,.2f}", 0, new_x=XPos.LMARGIN, new_y=YPos.NEXT, align='R')

    pdf.set_x(130)
    pdf.cell(35, 8, "Tax:", 0, new_x=XPos.RIGHT, new_y=YPos.TOP, align='R')
    pdf.cell(40, 8, f"{currency_symbol}{po_data.tax:,.2f}", 0, new_x=XPos.LMARGIN, new_y=YPos.NEXT, align='R')

    pdf.set_x(130)
    pdf.cell(35, 8, "TOTAL:", 0, new_x=XPos.RIGHT, new_y=YPos.TOP, align='R')
    pdf.cell(40, 8, f"{currency_symbol}{po_data.total:,.2f}", 0, new_x=XPos.LMARGIN, new_y=YPos.NEXT, align='R')

    # Save the PDF
    final_output_path = os.path.join(output_path, f"Generated_PO_{po_data.po_number}.pdf")
    pdf.output(final_output_path)
    print(f"\n--- Successfully generated new PO: {final_output_path} ---")


# --- Main Execution ---
if __name__ == "__main__":
    print(f"--- Starting PO Extraction and Generation Process for: {INPUT_FILE_PATH} ---")

    extractor = None
    if TEST_FILE_NAME.lower().endswith('.pdf'):
        if '111651' in TEST_FILE_NAME:
            extractor = IOSouthExtractor(INPUT_FILE_PATH)
        elif 'dandh' in TEST_FILE_NAME.lower():
            extractor = DandHExtractor(INPUT_FILE_PATH)
    elif TEST_FILE_NAME.lower().endswith('.csv'):
        if 'synnex' in TEST_FILE_NAME.lower() or 'emailquote' in TEST_FILE_NAME.lower():
            extractor = TDSynnexExtractor(INPUT_FILE_PATH)

    if extractor:
        try:
            purchase_order_data = extractor.extract_purchase_order()

            if purchase_order_data:
                generate_po_pdf(purchase_order_data, OUTPUT_DIR)
            else:
                print("\n--- Process failed: Could not extract complete Purchase Order data. ---")

        except FileNotFoundError as e:
            print(f"Error: {e}")
        except Exception as e:
            print(f"An unexpected error occurred during processing: {e}")
    else:
        print(f"Error: No extractor found for file type/name: {TEST_FILE_NAME}. Please check TEST_FILE_NAME or implement a new extractor.")

    print("\n--- Extraction and Generation Complete ---")

# --- NEXT STEPS (FUTURE DEVELOPMENT) ---
# 1. Adapt extraction for other quote types (e.g., DandH-Quote-11931304-0.Pdf)
#    This will likely involve different regex patterns and/or table_areas for camelot.
#    You might create a function or class that handles different vendor formats.

# 2. Structure Extracted Data: Combine df_line_items and quote_data into a single,
#    standardized Python object (e.g., a dictionary or custom class) that represents
#    all the information needed for a PO.

# 3. Generate PO PDF: Use a library like ReportLab or FPDF to programmatically create
#    a new PO PDF document using the structured data.
#    This will involve defining the layout (headers, tables, totals, signature lines).

# 4. Implement simple User Interface: Allow users to specify which quote PDF to process.
#    Could be a simple command-line argument using 'argparse'.

# 5. Add Advanced Validation/AI: As discussed earlier, intelligent validation or
#    more robust (AI-powered) extraction for highly variable documents.

assad